%!TEX root=finmath2.tex

\chapter{Метод конечных разностей для модели Хестона}
\label{ch:adi}

В этом дополнении мы покажем, как дискретизировать уравнение с частными производными для цены платежного обязательства в модели Хестона, чтобы решать его методом конечных разностей.
Мы также обсудим метод переменных направлений, который позволяет ускорить решение систем линейных разностных уравнений, возникающих на каждом шаге временной сетки.

Приводимые здесь рассуждения весьма универсальны и могут быть распространены на другие модели стохастической волатильности.


\section{Уравнение с частными производными для цены платежного обязательства}

Рассмотрим платежное обязательство $X=f(S_T)$ в модели Хестона.
Будем считать, что безрисковая процентная ставка и ставка дивидендной доходности равны нулю, но дальнейшие рассуждения нетрудно переносятся и на общий случай.
Пусть $U_t^X$ обозначает безарбитражную цену%
\footnote{В случае ненулевой процентной ставки здесь будет удобнее использовать недисконтированную цену, которая задается по той же формуле, \te\ без дисконтирующего множителя перед математическим ожиданием.} обязательства $X$:
\[
U_t^X = \E(X \mid \F_t).
\]
Как следует из формулы \fc, для достаточно хороших функций $f$ цена $U_t^X$ имеет вид $U(t,X_t,V_t)$, 
где функция $U$ удовлетворяет уравнению
\begin{align}
\label{adi:pde}
&\prt Ut + \mathcal{L} U = 0, \qquad t\in[0,T],\ s>0,\ v>0,\\
\label{adi:boundary}
&U(T,s,v) = f(s), \qquad s>0,\ v>0,
\end{align}
с дифференциальным оператором
\[
\mathcal{L} = \kappa(\theta-v)\prt{}v + \frac 12 s^2v \prtt {}s + \frac12 \sigma^2v \prtt {}v + \sigma\rho sv \Prtt{}sv.
\]

Будем искать функцию $U$ численно на множестве $[0,T]\times[0,s_{\max}]\times[0,v_{\max}]$, где значения $s_{\max}$ и $v_{\max}$ выбираются достаточно большими, так что процесс $(S_t,V_t)$ достигает соответствующих границ  с малой вероятностью. 
Тогда к решаемому уравнению нужно добавить краевые условия при $s=0$, $s=s_{\max}$ и $v=0$, $v=v_{\max}$. Они, вообще говоря, зависят от рассматриваемого платежного обязательства.
Покажем здесь, как задать краевые условия для опциона колл.

При $s=s_{\max}$ или $v=v_{\max}$ положим $U(t,s,v) = s - K$, так как при больших значениях цены базового актива или волатильности опцион исполнится с вероятностью близкой к 1, а потому его цену можно аппроксимировать ожиданием $\E(S_T-K\mid \F_t) = S_t - K$. 
При $s=0$ положим $U(t,0,v) = 0$, так как если цена базового актива стартует из нуля, то она будет всегда оставаться в нуле и, следовательно, опцион не исполнится. 
При $v=0$ воспользуемся тем, что уравнение \eqref{adi:pde} принимает вид
$U'_t + \kappa\theta U'_v = 0$.

Таким образом, для опциона колл к уравнениям \eqref{adi:pde}--\eqref{adi:boundary} добавляются краевые условия
\begin{align}
\label{adi:bc-first}
&U(t,0,v) = 0,\\
&U(t,s_{\max},v) = s_{\max} - K,\\
&U(t,s,v_{\max}) = s - K,\\
\label{adi:bc-last}
&\prt Ut(t,s,0) + \kappa\theta \prt Uv(t,s,0) = 0.
\end{align}


\section{Аппроксимация производных}

Для применения метода конечных разностей разобьем отрезки $[0,T]$, $[0,s_{\max}]$, $[0,v_{\max}]$ точками $t_i$, $s_m$, $v_n$, где индексы меняются от 0 до $I,M,N$, соответственно, и обозначим
\[
u_{m,n}^i = U(t_i, s_m, v_n).
\]
Будем считать, что по каждой координате берется разбиение с постоянным шагом%
\footnote{На практике имеет смысл использовать разбиения с переменным шагом, так как они дают большую точность вычислений (см., например, \cite{InTHoutFoulon10}).
Мы рассматриваем постоянный шаг ради простоты, так как иначе аппроксимация становится весьма громоздкой.}
$\Delta t$, $\Delta s$ или $\Delta v$. 
Задача состоит в том, чтобы найти все значения $u^i_{m,n}$.

Сначала зададим аппроксимацию производных по $s$ и $v$. Для этого обозначим $u_{m,n}(t) = U(t,s_m,v_n)$, где $t$ изменяется непрерывно от 0 до $T$.

Во внутренних точках прямоугольника  $[0,s_{\max}]\times[0,v_{\max}]$, \te\ для $m=1,\dots,M-1$ и $n=1,\dots,N-1$, будем использовать формулы
\begin{align*}
&\prt U{v}(t, s_m, v_n) = \frac{u_{m,n+1}(t) - u_{m,n-1}(t)}{2\Delta v},\\[0.5em]
&\prtt U{s}(t, s_m, v_n) = \frac{u_{m+1,n}(t) - 2u_{m,n}(t) + u_{m-1,n}(t)}{(\Delta s)^2},\\[0.5em]
&\prtt U{v}(t, s_m, v_n) = \frac{u_{m,n+1}(t) - 2u_{m,n}(t) + u_{m,n-1}(t)}{(\Delta v)^2},\\[0.5em]
&\Prtt U vs(t, s_m, v_n) = \frac{u_{m+1,n+1}(t) - u_{m-1,n+1}(t) - u_{m+1,n-1}(t) + u_{m-1,n-1}(t)}{4\Delta s \Delta v}.
\end{align*}
Терминальное условие, очевидно, соответствует равенству
\[
u_{m,n}(T) = (s_m-K)^+,
\]
а краевые условия \eqref{adi:bc-first}--\eqref{adi:bc-last} для опциона колл эквивалентны тому, что 
\begin{align*}
&u_{0,n}'(t) = 0,\qquad u_{M,n}'(t) = 0,\qquad u_{m,N}'(t) = 0,\\
&u'_{m,0}(t) + \kappa\theta \frac{u_{m,1}(t) - u_{m,0}(t)}{\Delta v} = 0.
\end{align*}
Штрихи здесь обозначают производную по $t$.
В первых трех условиях воспользовались тем, что в рассматриваемой задаче функция $U(t,s,m)$ постоянна на трех границах $s=0$, $s=s_{\max}$, $v=v_{\max}$, а последнее условие (соответствующее границе $v=0$) получено из уравнения \eqref{adi:pde} аппроксимацией частной производной по $v$ правосторонней разностью $(u_{m,1}(t) - u_{m,0}(t))/\Delta v$.

Собирая все вместе, получаем, что уравнение \eqref{adi:pde}, терминальное и граничные условия после аппроксимации производных превращаются в систему обыкновенных дифференциальных уравнений 
\begin{align}
\label{adi:ode}
&u'(t) + Lu(t) = 0, \qquad t\in[0,T],\\
&u_{m,n}(T) = (s_m-K)^+,
\end{align}
где $u(t)\colon [0,T] \to \R^{(M+1)\times (N+1)}$ "--- матричнозначная функция с компонентами $u_{m,n}(t)$. Коэффициент $L=(L_{m,n}^{m',n'})$ является тензором типа $(2,2)$; он умножается на матрицу $u$ по правилу
\[
(Lu)_{m,n} = \sum_{m'=0}^M\sum_{n'=0}^N L_{m,n}^{m',n'}u_{m',n'}.
\]
В явном виде, для $1\le m \le M-1$ и $1\le n \le N-1$ имеем
\begin{align*}
&L_{m,n}^{m-1,n-1} = \frac{\sigma\rho s_mv_n}{4\Delta s\Delta v}, \qquad
  L_{m,n}^{m-1,n} = \frac{s_m^2v_n}{2(\Delta s)^2}, \qquad
  L_{m,n}^{m-1,n+1} = -\frac{\sigma\rho s_mv_n}{4\Delta s\Delta v},\\[0.5em]
&L_{m,n}^{m,n-1} = -\frac{\kappa(\theta-v_n)}{2\Delta v} + \frac{\sigma^2v_m}{2(\Delta v)^2}, \qquad
  L_{m,n}^{m,n} = - \frac{s_m^2v_n}{(\Delta s)^2} - \frac{\sigma^2v_n}{(\Delta v)^2},\\[0.5em]
  &L_{m,n}^{m,n+1} = \frac{\kappa(\theta-v_n)}{2\Delta v} + \frac{\sigma^2v_m}{2(\Delta v)^2},\\[0.5em]
&L_{m,n}^{m+1,n-1} = -\frac{\sigma\rho s_mv_n}{4\Delta s\Delta v}, \qquad
  L_{m,n}^{m+1,n} = \frac{s_m^2v_n}{2(\Delta s)^2}, \qquad
  L_{m,n}^{m+1,n+1} = \frac{\sigma\rho s_mv_n}{4\Delta s\Delta v};
\end{align*}
для $n=0$ и $1\le m \le M-1$ имеем
\[
L_{m,0}^{m,1} = \frac{\kappa\theta}{\Delta v}, \qquad L_{m,0}^{m,0} = -\frac{\kappa\theta}{\Delta v};
\]
все остальные компоненты $L$ равны 0.

Теперь аппроксимируем производную по $t$.
Общая разностная схема с весом $\theta \in [0,1]$ выглядит следующим образом:
\begin{equation}
\label{adi:scheme}
\frac{u^i - u^{i-1}}{\Delta t} + (\theta L u^{i-1} + (1-\theta)L u^i)=0,
\end{equation}
где $u^i$ "--- матрица размера $(M+1)\times(N+1)$, приближающая $u(t_i)$.
Выбор $\theta=0$ дает \emph{явную схему}, $\theta=1$ "--- \emph{неявную схему}, а $\theta=1/2$ "--- \emph{схему Кранка"--~Николсона}.

В явной схеме матрицы $u^{i-1}$ легко находятся обратной индукцией для $i=I,I-1,\dots,0$ по формуле
\[
u^I_{m,n} = (s_m-K)^+,\qquad u^{i-1} = u^i + Lu^i\Delta t.
\]
Недостаток явной схемы заключается в том, что она устойчива, только если $\Delta t$ мало по сравнению с $\Delta s$ и $\Delta v$, а именно $\Delta t$ должно быть по порядку не больше, чем $(\Delta s)^2$ и $(\Delta v)^2$ (подробнее см.~\cite{GulinSamarski89}, ч.~III, гл.~4, \S\,4; о понятиях сходимости, устойчивости и аппроксимации разностных схем см.~также лекцию 13 курса \intro).

Неявная схема и схема Кранка--Николсона устойчивы, но для них формула \eqref{adi:scheme} становится системой из $(M+1)(N+1)$ линейных уравнений на компоненты матрицы $u^{i-1}$.
При больших $M$ и $N$ ее решение с помощью общих методов линейной алгебры является вычислительно трудоемкой задачей (порядка $O(N^3M^3)$ операций), поэтому применение этих схем в таком виде затруднительно.

Ниже мы рассмотрим варианты разностных схем, относящихся к \emph{методу переменных направлений} (ADI, Alternating-direction implicit).
Этот метод основан на приближении двумерной задачи \eqref{adi:scheme} для переменных $s,v$ одномерными задачами по каждой переменной, которые сравнительно легко решаются методом прогонки.


\section{Метод переменных направлений}
\subsection{Случай нулевой корреляции}
Чтобы нагляднее объяснить суть метода, рассмотрим сначала случай $\rho=0$, который удобен тем, что в рассматриваемом уравнении с частными производными не возникает слагаемого со смешанной производной.

Представим тензор $L$ в виде суммы
\[
L =  A + B,
\]
где тензор $A$ содержит компоненты $L$, возникающие из аппроксимации производных по $s$, а $B$ "--- компоненты, возникающие из аппроксимации производных по $v$.
А именно,
\begin{align*}
&A_{m,n}^{m-1,n} = A_{m,n}^{m+1,n} =  \frac{s_m^2v_n}{2(\Delta s)^2}\ (=L_{m,n}^{m+1,n} = L_{m,n}^{m-1,n}), \\
&A_{m,n}^{m,n} = - \frac{s^2_mv_n}{(\Delta s)^2};
\end{align*}
тензор $B$ получается аналогично.

В \emph{схеме Дугласа"--~Рэчфорда} (J. Douglas, H. Rachford) матрица $u^{i-1}$ получается из $u^i$ за два шага: сначала из $u^i$ строится <<промежуточная>> матрица $u^{i-\frac12}$ посредством решения системы \eqref{adi:pr-1} ниже, а затем из нее получается $u^{i-1}$ как решение системы \eqref{adi:pr-2}:
\begin{align}
\label{adi:pr-1}
&\frac{u^{i-\frac12} - u^{i}}{\Delta t} = A u^{i-\frac12} + B u^{i},\\
\label{adi:pr-2}
&\frac{u^{i-1} - u^{i-\frac12}}{\Delta t} = B u^{i-1} - B u^{i}.
\end{align}
Обе этих системы эффективно решаются методом прогонки. Действительно, чтобы решить систему \eqref{adi:pr-1} нужно для каждого фиксированного $n=0,\dots,N$ рассмотреть ее как систему уравнений на переменные $u^{i-\frac12}_{m,n}$, где $m=0,\dots,M$: 
\begin{multline*}
\frac{u^{i-\frac12}_{m,n} - u^i_{m,n}}{\Delta t} 
  = A_{m,n}^{m-1,n}u^{i-\frac12}_{m-1,n} + A_{m,n}^{m,n}u^{i-\frac12}_{m,n} +  A_{m,n}^{m+1,n}u^{i-\frac12}_{m+1,n} \\
  + B_{m,n-1}^{m,n-1}u^i_{m,n-1} + B_{m,n}^{m,n}u^i_{m,n} + B_{m,n}^{m,n+1}u^i_{m,n+1}
\end{multline*}
(компоненты тензоров с отрицательными индексами положим равными нулю).
Эта система является трехдиагональной и метод прогонки позволяет решить ее за $O(M)$ операций.
Суммарно для всех $n$ будет затрачено $O(MN)$ операций на решение системы \eqref{adi:pr-1}.
Такой же порядок сложности и у системы \eqref{adi:pr-2}.

Найдя $u^{i-1}$ процедура повторяется для $u^{i-2}$ и \td\ 
Таким образом, процесс нахождения матриц $u^i$ состоит в том, что поочередно решаются системы уравнений вдоль направлений $s$ и $v$, что и дает название методу.

\begin{remark}
Поясним, откуда берутся уравнения \eqref{adi:pr-1}--\eqref{adi:pr-2}.
Как известно, линейное дифференциальное уравнение $u'(t) + L u(t)=0$ имеет решение 
\[
u(t) = e^{(T-t)L}u(T),
\]
где $e^{(T-t)L}$ "--- экспонента%
\footnote{Экспонента оператора определяется как $e^{L} = \sum_{n=0}^\infty \frac{L^n}{n!}$, где $L^n = L\circ\ldots\circ L$.} тензора $L$, рассматриваемого как непрерывный линейный оператор на пространстве $\R^{(M+1)\times(N+1)}$.
В частности, 
\[
u(t-\Delta t) = e^{\Delta t L}u(t) = e^{\Delta t(A+B)}u(t).
\]
Справедливо разложение
\begin{multline*}
e^{\Delta t(A+B)} = I + \Delta t A + \Delta t B + O((\Delta t)^2) \\= 
(I-\Delta t B)^{-1}(I-\Delta t A)^{-1} + O((\Delta t)^2) \\=
(I -\Delta t B)^{-1} \bigl((I-\Delta t A)^{-1}(I+\Delta t B) - \Delta tB\bigr) + O((\Delta t)^2),
\end{multline*}
где $I$ "--- тождественный оператор.
Отсюда получаем приближенное решение
\[
u(t-\Delta t) \approx (I +\Delta t B)^{-1} \bigl((I+\Delta t A)^{-1}(I+\Delta t B) - \Delta tB\bigr) u(t).
\]
Остается непосредственно убедиться, что если исключить $u^{i-\frac12}$ из уравнений \eqref{adi:pr-1}--\eqref{adi:pr-2}, то $u^{i-1}$ будет выражаться через $u^i$ по такой же формуле.
\end{remark}

\begin{remark}
Схема Дугласа"--~Рэчфорда имеет порядок аппроксимации 1 (так как в разложении экспоненты были отброшены члены $O((\Delta t)^2)$) и можно показать, что она является устойчивой.
Если ее немного модифицировать, то получится \emph{схема Писмена"--~Рэчфорда} (D.\ Peaceman, H. Rachford), имеющая порядок аппроксимации 2.
При этом схема Дугласа"--~Рэчфорда обобщается на три и более измерений по пространственной переменной, а схема Писмена"--~Рэчфорда нет.
Подробнее о схеме Писмена"--~Рэчфорда, см., например, \cite{GulinSamarski89}, ч.~III, гл.~4, \S\,4.
\end{remark}
% Схема ПР
% \begin{align*}
% &\frac{u^{i-\frac12} - u^i}{\Delta t/2} = A u^{i-\frac12} + B u^{i},\\
% &\frac{u^{i-1} - u^{i-\frac12}}{\Delta t/2} = A u^{i-\frac12} + B u^{i-1},
% \end{align*}
% Аппроксимация экспоненты
% \[
% e^{-\Delta t(A+B)} = \left(I + \frac{\Delta t}{2}A\right)^{-1} \left(I - \frac{\Delta t}{2}B\right) \left(I + \frac{\Delta t}{2}B\right)^{-1} \left(I - \frac{\Delta t}{2}A\right) + O((\Delta t)^3),
% \]


\subsection{Случай произвольной корреляции}
Представим тензор $L$ в виде суммы
\[
L =  A + B + C,
\]
где $A,B$ такие же, как и в предыдущем разделе, а тензор $C$ содержит компоненты $L$, возникающие из аппроксимации смешанной производной:
\[
C_{m,n}^{m-1,n-1} = C_{m,n}^{m+1,n-1} = \frac{\sigma\rho s_mv_n}{4\Delta s \Delta v},\qquad
C_{m,n}^{m-1,n+1} = C_{m,n}^{m+1,n+1} = -\frac{\sigma\rho s_mv_n}{4\Delta s \Delta v}.
\]
Тогда схему Дугласа"--~Рэчфорда можно обобщить следующим образом:
\begin{align}
\label{adi:d-1}
&\frac{u^{i-\frac12} - u^i}{\Delta t} = A u^{i-\frac12} + (B+C) u^{i},\\
\label{adi:d-2}
&\frac{u^{i-1} - u^{i-\frac12}}{\Delta t} = B u^{i-1} - B u^{i}.
\end{align}
Для смешанной производной здесь в сущности используется явная схема. 

Известно, что схема \eqref{adi:d-1}--\eqref{adi:d-2} имеет порядок аппроксимации 1 и является устойчивой.
Существует схемы порядка аппроксимации 2 (например, \emph{схема Крейга"--~Снейда}); мы их здесь не приводим, детали можно найти в статье \cite{InTHoutFoulon10}.
