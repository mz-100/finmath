%!TEX root=finmath1.tex
\chapter{Мартингалы}
\label{ch:mart}
\chaptertoc

Мартингал "--- это случайная последовательность (или процесс) такая, что математическое ожидание ее будущих значений равно текущему значению.

В финансовой математике мартингалы играют чрезвычайно важную роль, потому что при отсутствии арбитража дисконтированные цены активов должны являться мартингалами относительно так называемых эквивалентных мартингальных мер (это обобщение понятия риск-нейтральной вероятности).

Чтобы ввести понятие мартингала нам потребуются понятия условного математического ожидания и фильтрации на вероятностном пространстве, с которых мы и начнем эту лекцию.

Почти все результаты будут приведены без доказательств.
Их можно найти, например, в книге \cite{Shiryaev04} (см.~главу II.7 об условном математическом ожидании и главу VII.1 о мартингалах).


\section{Условное математическое ожидание}
\subsection{Подготовительные рассуждения}

Определение условного математического ожидания в полной общности может показаться слишком абстрактным, поэтому начнем с частных случаев.

Для начала рассмотрим вероятностное пространство с конечным множеством исходов.
Без ограничения общности будет считать, что вероятности всех исходов строго положительны. Случайные величины на таком пространстве принимают конечное число значений.

Если $X$ "--- случайная величина, а $A$ "--- случайное событие, то определим условное математическое ожидание $X$ при условии $A$ по формуле
\[
\E(X\mid A) = \sum_{i=1}^n x_i \P(X=x_i\mid A),
\]
\te\ заменив в определении математического ожидания обычные вероятности на условные. 
Интерпретировать $\E(X\mid A)$ можно как среднее значение величины $X$ в случае, когда мы знаем, что произошло событие $A$.

Пусть теперь $X$ и $Y$ "--- две случайные величины.
Если значение $Y$ известно, то вычислить условное ожидание $X$, учитывая эту информацию, можно как $\E(X\mid Y=y)$, где ``$Y=y$'' означает соответствующее случайное событие.
Имея это ввиду, определим условное ожидание $X$ при условии $Y$ как
\[
\E(X\mid Y) = g(Y),\ \text{где}\ g(y) = \E(X\mid Y=y).
\]
Отметим, что, по определению, $\E(X\mid Y)$ само является случайной величиной.
Это удобно, в частности, потому что позволяет применять к нему те же операции, что и к обычным случайным величинам.

Нетрудно показать, что условное ожидание обладает следующими свойствами.
Если $X,Y,Z$ "--- случайные величины, а $f(y)$ "--- произвольная функция, то 
\begin{align*}
&\E(X+Z \mid Y) = \E(X\mid Y) + \E(Z\mid Y),\\
&\E(f(Y)X \mid Y) = f(Y)\E(X\mid Y),\\
&\E(\E(X\mid Y)) = \E X.
\end{align*}
Первое свойство "--- это линейность условного ожидания.
Второе свойство "--- более сильная форма линейности, которая позволяет выносить из условного ожидания множители, функционально зависящие от $Y$ (как из обычного ожидания можно выносить константы).
Третье свойство означает, что условное ожидание дает несмещенную оценку для обычного ожидания%
\footnote{Понятие несмещенной оценки вводится в курсе математической статистики.
Дальше оно нам не потребуется.}.

В качестве следствия из второго и третьего равенств получаем, что 
\begin{equation}
\label{mart:defining-property}
\E(f(Y)X) = \E(f(Y)\E(X\mid Y)).
\end{equation}
Оказывается, формула \eqref{mart:defining-property} является определяющим свойством условного ожидания в следующем смысле: для любых случайных величин $X,Y$ (пока все еще на конечном вероятностном пространстве), существует единственная случайная величина $U$ (а именно, $U=\E(X\mid Y)$) такая, что она может быть представлена в виде $U=g(Y)$, и для любой функции $f(y)$ выполнено
\[
\E(f(Y)X) = \E(f(Y)U).
\]

Используя эту идею, распространим понятие $\E(X\mid Y)$ на произвольные вероятностные пространства.
Конструкция дается в два этапа: сначала для неотрицательных $X$, а потом для произвольных.

Можно показать, что для случайной величины $X\ge 0$ и произвольной случайной величины $Y$ найдется п.н.-единственная расширенная\footnote{То есть может принимать значение $+\infty$} величина $U\ge0$ такая, что $U=g(Y)$, и для любой неотрицательной функции $f(y)$ выполнено равенство
\[
\E(f(Y)X) = \E(f(Y)U).
\]
Тогда положим по определению $\E(X\mid Y) = U$.

Для произвольной случайной величины $X$ определим условное ожидание как $\E(X\mid Y) = \E(X^+\mid Y) - \E(X^-\mid Y)$ в предположении, что с вероятностью 1 не возникает неопределенности вида $\infty-\infty$ (в противном случае считается, что $\E(X\mid Y)$ не определено).
Здесь, как обычно, $X^+ = \max(X,0)$, $X^- = \max(-X,0)$; в частности, $X=X^+-X^-$. При таком определении $\E(X\mid Y)$ может принимать значения $\pm\infty$.

Следующий шаг будет состоять в том, чтобы распространить понятие условного ожидания на ожидание относительно $\sigma$-алгебры: $\E(X \mid \G)$. Сигма-алгебра $\G$ играет роль некоторой абстрактной информации, которая нам доступна. 


\subsection{Определение и свойства условного математического ожидания}
Будем считать заданным вероятностное пространство $(\Omega, \F,\P)$, а также некоторую $\sigma$-алгебру $\G\subseteq \F$.

\begin{proposition}
\label{mart:p:expectation}
Пусть $X\ge0$ "--- случайная величина. Тогда существует п.н.-единственная расширенная случайная величина $U$ такая, что для любой неотрицательной $\G$-измеримой случайной величины $Z$ выполнено равенство
\[
\E(XZ) = \E(UZ).
\]
\end{proposition}

\begin{definition}
Такая величина $U$ называется \emph{условным математическим ожиданием} $X$ относительно $\G$ и обозначается $\E(X\mid \G)$.
\end{definition}

\begin{remark}
В формулировке предложения \ref{mart:p:expectation} можно заменить $\G$-измеримую случайную величину $Z$ на индикатор события $A\in \G$ и получится эквивалентное утверждение.
\end{remark}


\begin{definition}
Если $X$ "--- произвольная случайная величина такая, что
\begin{equation}
\label{mart:finite-cond-exp}
\max(\E(X^+\mid \G),\ \E(X^-\mid \G))<\infty\ \text{п.н.},
\end{equation}
то положим по определению $\E(X\mid \G)=\E(X^+\mid \G) - \E(X^-\mid \G)$.
Если условие \eqref{mart:finite-cond-exp} не выполнено, то считаем, что $\E(X\mid \G)$ не определено.
\end{definition}

\begin{remark}
Под условным ожиданием $\E(X\mid Y)$ одной случайной величины относительно другой понимают, по определению, $\E(X\mid \sigma(Y))$, где $\sigma(Y)$ обозначает $\sigma$-алгебру, порожденную случайной величиной $Y$. 
Можно показать, что такое определение согласуется с определением из предыдущего раздела.
Для этого нужно воспользоваться тем фактом, что любая $\sigma(Y)$-измеримая случайная величина является функцией от $Y$.

В частности, $\E(X\mid Y) = g(Y)$ с некоторой измеримой функцией $g(y)$, для которой  традиционно применяется обозначение $g(y) = \E(X\mid Y=y)$.
\end{remark}

\begin{proposition}
Если $\E|X|<\infty$, то $\E(X\mid \G)$ определено и конечно п.н.
\end{proposition}

\begin{proposition}
Выполнены следующие свойства (при условии, что корректно определены все ожидания, входящие в них).

\begin{alphenum}
\item $\E(X + Y \mid \G) = \E(X\mid \G) + \E(Y\mid \G)$.

\item $\E(\E(X\mid \G)) = \E X$.

\item $\E(X\mid\G) = \E X$, если $X$ не зависит\footnote{Напомним, что случайная величина $X$ называется не зависящей от $\sigma$-алгебры $\G$, если независимы любые события $A\in \G$ и $\{\omega: X(\omega)\in B\}$, где $B$ "--- произвольное борелевское множество.} от $\G$.
В частности, $\E(X\mid\G) = \E X$, если $\G=\{\emptyset, \Omega\}$.

\item Если $X$ является $\G$-измеримой, то $\E(XY\mid \G) = X\E(Y\mid \G)$.
В частности, $\E(X\mid \G) = X$ для $\G$-измеримых случайных величин.

\item Если $\G_1 \subseteq \G_2$, то $\E(\E(X\mid \G_2) \mid \G_1) = \E(X\mid \G_1)$ (телескопическое свойство). 

\item Если функция $f$ выпукла, то $\E(f(X)\mid \G) \ge f(\E(X\mid \G))$ (неравенство Йенсена).
\end{alphenum}
\end{proposition}

\begin{remark}
Как вычислить условное математическое ожидание?
В общем случае явного выражения не получить; можно только попробовать упростить выражение, содержащее условные ожидания, используя свойства выше.

Но в двух конкретных случаях условное ожидание можно посчитать явно.
Во-первых, если случайные величины $X$, $Y$ приминают конечное или счетное число значений, то, аналогично формуле в начале раздела, для любой функции $h(y)$ имеем
\[
\E(h(X)\mid Y) = g(Y), \qquad g(y) = \sum_i h(x_i)\P(X=x_i\mid Y=y).
\] 
Во-вторых, если случайные величины $X,Y$ обладают совместной плотностью $p(x,y)$, а, следовательно, $Y$ обладает плотностью $g(y) = \int_\R p(x,y) dx$, то
\[
\E(h(X)\mid Y) = f(Y), \qquad f(y) = \int_{\R} h(x) p(x\mid y) dx,
\]
где $p(x\mid y)$ -- \emph{условная плотность} $X$ при условии $Y$, определенная следующим образом:
\[
p(x\mid y) =
\begin{cases}
\dfrac{p(x,y)}{g(y)}, &\text{если}\ g(y)>0,\\
0,                    &\text{если}\ g(y)=0.
\end{cases}
\]
\end{remark}


\section{Фильтрованные вероятностные пространства}

Пусть задано вероятностное пространство $(\Omega,\F,\P)$.

\begin{definition}
\emph{Фильтрацией} $\FF=(\F_t)_{t=0}^T$ на $(\Omega,\F,\P)$ называется последовательность вложенных $\sigma$-алгебр
\[
\F_0 \subseteq \F_1 \subseteq\ldots \subseteq \F_T \subseteq \F.
\]
Совокупность $(\Omega,\F,\FF,\P)$ называется \emph{фильтрованным вероятностным прос\-транством.}
\end{definition}

Элементы фильтрации $\F_t$ интерпретируются как информация, доступная к моменту времени $t$: в момент $t$ мы можем определить, произошло ли некоторое случайное событие $A$ или нет, только если $A\in \F_t$.
Вложение $\F_t\subseteq \F_{t+1}$ означает, что со временем информации не становится меньше.

\begin{remark}
Далее мы будем часто предполагать, что $\F_0=\{\emptyset,\Omega\}$.
Тогда любая случайная величина, измеримая относительно $\F_0$, является константой.
Это соответствует тому, что случайные величины, реализующиеся в момент времени $t=0$ (<<сейчас>>), уже известны.

Отметим, что, горизонт времени $T$ может быть бесконечным.
Однако в дальнейшем мы, в основном, будем рассматривать только случай конечного $T$.
\end{remark}

\begin{example}
Важным примером фильтрации является \emph{фильтрация, порожденная случайной последовательностью}.
Если $X_0,\dots,X_T$ "--- случайные величины, то положим $\F_t = \sigma(X_0,\dots,X_t)$, где $\sigma(\dots)$ обозначает $\sigma$-алгебру, порожденную случайными величинами%
\footnote{Минимальная $\sigma$-алгебра, относительно которой все случайные величины из набора измеримы.}.
Ясно, что $\F_t^X\subseteq \F_{t+1}^X$, поэтому $\FF^X = (\F_t^X)_{t=0}^T$ действительно задает фильтрацию.

Если последовательность $X_t$ начинается с $t=1$, то обычно полагают $\F_0^X=\{\emptyset,\Omega\}$ и $\F_t^X = \sigma(X_1,\dots,X_t)$.
Снова получается фильтрация.
\end{example}

\begin{definition}
По отношению к фильтрации $\FF$ случайная последовательность $X=(X_t)_{t=0}^T$ называется
\begin{itemize}
\item \emph{согласованной} с $\FF$, если все $X_t$ измеримы относительно $\F_t$,
\item \emph{предсказуемой} относительно $\FF$, если все $X_t$ измеримы относительно $\F_{t-1}$.
\end{itemize}
(В определении предсказуемой последовательности для $t=0$ полагается, что $\F_{-1}=\F_0$, или можно считать, что отсчет $X_t$ начинается c $t=1$.)
\end{definition}

Смысл определения согласованности состоит в том, что значение $X_t$ становится известным к моменту времени $t$, а предсказуемость означает, что $X_t$ известно уже в момент $t-1$.
Например, далее мы увидим, что цены акций, как правило, моделируются согласованными последовательностями, а процентные ставки предсказуемыми (так как ставка $r_t$ по вкладу на период $[t-1,t]$ уже известна в начале периода).

\begin{proposition}
Пусть фильтрация $\FF^X$ порождена случайной последовательностью $X$.
Тогда любая согласованная последовательность представима в виде $Y_t = f_t(X_0,\dots,X_t)$ для некоторых неслучайных функций $f_t$, а любая предсказуемая последовательность представима в виде $Y_t = f_t(X_0,\dots,X_{t-1})$.
\end{proposition}


\section{Мартингалы}
\subsection{Определение и примеры}

Пусть задано фильтрованное вероятностное пространство $(\Omega,\F,\FF,\P)$.
Время будет ограничено конечным моментом $T$, но все дальнейшие определения и примеры переносятся на случай бесконечного горизонта времени.

\begin{definition}
\emph{Мартингалом} относительно фильтрации $\FF$ называется согласованная случайная последовательность $X=(X_t)_{t=0}^T$ такая, что
\begin{alphenum}
\item $\E|X_t|<\infty$ для всех $t=0,\dots,T$,
\item $\E(X_{t+1}\mid \F_t) = X_t$ для всех $t=0,\dots,T-1$ (\emph{мартингальное свойство}).
\end{alphenum}
\end{definition}

Мартингальное свойство означает, что наилучшим прогнозом значения последовательности <<на завтра>> является значение <<сегодня>>.

\begin{remark}
Мартингал определяется по отношению к фильтрации.
Однако, если из контекста ясно, о какой фильтрации идет речь, мы будем опускать упоминание фильтрации.
\end{remark}

\begin{proposition}
Если $X$ "--- мартингал, то $\E(X_t\mid \F_s) = X_s$ и $\E X_t = \E X_s$ для всех $s\le t$.
\end{proposition}
\begin{proof}
Докажем по индукции. 
Для $t=s$ утверждение очевидно.
Если утверждение доказано для $t$, то, пользуясь телескопическим свойством, получаем
\[
\E (X_{t+1} \mid \F_s) = \E(\E(X_{t+1}\mid \F_t)\mid \F_s) = \E(X_t\mid \F_s) = X_s.
\]
Кроме того, если взять ожидания от обеих частей этого равенства, то получим $\E X_{t+1} = \E X_s$.
Следовательно верен шаг индукции.
\end{proof}

\begin{example}[случайное блуждание]
Пусть $\xi = (\xi_t)_{t=1}^T$ является последовательностью независимых случайных величин, причем $\E\xi_t=0$.
Положим $\F_0 = \{\emptyset,\Omega\}$ и $\F_t = \sigma(\xi_1,\dots,\xi_t)$.
Тогда для произвольного $x\in\R$ последовательность 
\[
X_t = x + \xi_1 + \ldots + \xi_t
\]
является мартингалом относительно $\FF$.
Действительно, ясно, что $X$ согласована с $\FF$ и $\E|X_t|<\infty$.
Мартингальное свойство выполнено в силу равенства
\[
\E(X_{t+1}\mid \F_t) = \E (X_t + \xi_{t+1}\mid \F_t) = X_t + \E(\xi_{t+1}\mid \F_t) = X_t,
\]
где воспользовались тем, что $\E(\xi_{t+1}\mid \F_t) = \E \xi_{t+1} = 0$ в силу независимости.
\end{example}

\begin{example}[мультипликативное случайное блуждание]
Опять рассмотрим последовательность независимых случайных величин $\xi_t$ и порожденную ей фильтрацию, но будем предполагать, что $\E\xi_t=1$.
Тогда мартингалом является последовательность
\[
X_t = x\xi_1\cdot \ldots \cdot \xi_t.
\]

Доказательство аналогично предыдущему примеру. Действительно, имеем $\E(X_{t+1}\mid \F_t) = \E (X_t \xi_{t+1}\mid \F_t) = X_t\E(\xi_{t+1}\mid \F_t) = X_t$, где 
воспользовались таким известным фактом: если случайные величины $\xi_t$ независимы и имеют конечное ожидание, то $\xi_1\cdot\ldots\cdot\xi_t$ тоже имеет конечное ожидание, равное произведению ожиданий $\xi_t$.
\end{example}

\begin{example}[мартингалы Леви]
Для произвольной фильтрации $\FF$ и произвольной случайной величины $\xi$ с конечным ожиданием положим
\[
X_t = \E(\xi\mid \F_t).
\]
Тогда последовательность $X_t$ является мартингалом, называемым \emph{мартингалом Леви}.

Действительно, согласованность очевидна.
Конечность ожидания $X_t$ следует из того, что $\E X_t = \E(\E(\xi\mid \F_t)) = \E \xi_t$. 
Мартингальное вытекает из применения телескопического свойства: 
\[
\E(X_{t+1} \mid \F_t) = \E(\E(\xi\mid\F_{t+1})\mid \F_t) = \E(\xi \mid \F_t) = X_t.
\]

Заметим, что в случае конечного горизонта времени $T$ любой мартингал является мартингалом Леви, так как $X_t = \E(X_T\mid \F_t)$. В случае бесконечного $T$ это может быть не так из-за того, что не всегда можно определить $X_\infty$.
\end{example}

\subsection{Мартингальные преобразования}
\begin{definition}
\emph{Мартингальным преобразованием} называется согласованная последовательность $X=(X_0)_{t=0}^T$, представимая в виде
\[
X_t = X_0 + \sum_{s=1}^t H_s \Delta M_s,
\]
где $X_0$ "--- $\F_0$-измеримая случайная величина с $\E|X_0|<\infty$, случайная последовательность $H=(H_t)_{t=1}^T$ является предсказуемой, а $M=(M_t)_{t=0}^T$ "--- мартингал. Символ $\Delta$ обозначает приращение последовательности (\te\ $\Delta M_s = M_s - M_{s-1}$).
\end{definition}

Мартингальные преобразования играют важную роль в финансовой математике, так как ими являются цены портфелей торговых стратегий относительно эквивалентных мартингальных мер (об этом --- в следующей лекции).

В общем случае мартингальное преобразование не является мартингалом, но справедливо следующее утверждение, дающее достаточное условие для мартингальности $X_t$.

\begin{proposition}
\label{mart:martingale-transform}
Если $X=(X_t)_{t=0}^T$ -- мартингальное преобразование такое, что $\E X_T^+ < \infty$ или $\E X_T^- < \infty$, то $X$ является мартингалом.
\end{proposition}

В качестве следствия отсюда можно получить, что если последовательность $H$ равномерно ограничена (т.е.\ $|H_t| < c$ для всех $t$, где $c$ "--- константа), то мартингальное преобразование $X$ является мартингалом.
Это следует из оценки $\E |X_T| \le \E|X_0| + c\sum_{s=1}^T \E|\Delta M_s| < \infty$.

\medskip
Известно, что класс мартингальных преобразований совпадает с классом обобщенных мартингалов и классом локальных мартингалов. Дадим соответствующие определения и сформулируем результат для обобщенных мартингалов (локальные мартингалы мы сейчас обсуждать не будем, но вернемся к ним в непрерывном времени при изучении стохастического интеграла).
Это, в частности, позволит нам легко доказать, что сумма или разность мартингальных преобразований является мартингальным преобразованием.

\begin{definition}
\emph{Обобщенным мартингалом} относительно фильтрации $\FF$ называется согласованная случайная последовательность $X=(X_t)_{t=0}^T$ такая, что
\begin{alphenum}
\item $\E|X_0| < \infty$ и $\E(|X_{t+1}|\mid \F_t) < \infty$ для всех $t=0,\dots,T-1$,
\item $\E(X_{t+1}\mid \F_t) = X_t$ для всех $t=0,\dots,T-1$.
\end{alphenum}
\end{definition}

Как видно, отличие обобщенного мартингала от обычного состоит в том, что вместо условия $\E|X_t|<\infty$ требуется более слабое условие $\E(|X_{t+1}|\mid \F_t) < \infty$. В частности, любой мартингал является обобщенным мартингалом, однако можно привести пример, когда обратное не верно.

\begin{proposition}
Последовательность $X=(X_t)_{t=0}^T$ является обобщенным мартингалом тогда и только тогда, когда она является мартингальным преобразованием.
\end{proposition}

\begin{corollary}
Сумма или разность мартингальных преобразований является мартингальным преобразованием.
\end{corollary}
\begin{proof}
Это следует из того, что, очевидно,  сумма или разность обобщенных мартингалов является обобщенным мартингалом.
\end{proof}

\summary

\begin{itemize}
\item Условное математическое ожидание $\E(X\mid \G)$ для неотрицательной случайной величины $X$ определяется как такая случайная величина $U$, что $\E(XZ) = \E(UZ)$ для любой неотрицательной $\G$-измеримой случайной величины $Z$.
Для произвольной случайной величины $X$ полагают $\E(X\mid\G) = \E(X^+\mid \G) - \E(X^-\mid \G)$, если \as\ не возникает неопределенности  $\infty-\infty$.

\item Фильтрацией $\FF=(\F_t)_{t=0}^T$ на вероятностном пространстве $(\Omega,\F,\P)$ называется семейство вложенных $\sigma$-алгебр $\F_0 \subseteq \F_1 \subseteq\ldots \subseteq \F_T \subseteq \F$, где $\F_t$ выражает информацию, доступную к моменту времени $t$.

\item Согласованная случайная последовательность $X_t$ называется мартингалом, если она имеет конечное математическое ожидание и выполнено мартингальное свойство $\E(X_{t+1}\mid \F_t) = X_t$.
Примеры мартингалов: случайное блуждание, мультипликативное случайное блуждание, мартингалы Леви.

\item Мартингальным преобразованием называется согласованная последовательность $X_t = X_0 + \sum_{s=1}^t H_s \Delta M_s$, где $M_t$ "--- мартингал, $H_t$ "--- предсказуемая последовательность, $\E|X_0|<\infty$. Мартингальное преобразование является мартингалом, если $\E X_T^+ < \infty$ или $\E X_T^- < \infty$. Сумма или разность мартингальных преобразований также является мартингальным преобразованием.
\end{itemize}
