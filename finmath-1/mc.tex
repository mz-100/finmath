\chapter{Метод \mc\ для модели \bs}
\label{ch:mc}
\chaptertoc

Метод \mc\ предназначен для вычисления математических ожиданий случайных величин с помощью симуляций.
В этой лекции мы обсудим его общие принципы, а также как применять его для вычисления цен платежных обязательств в модели \bs.


\section{Основные принципы}
\subsection{Сходимость выборочного среднего к математическому ожиданию}

Пусть необходимо вычислить математическое ожидание $\mu=\E X$.
Часто встречается ситуация, когда функция распределения случайной величины $X$ в явном виде не известна, но существует некоторый алгоритм для симуляции значений из распределения $X$.
Тогда $\mu$ можно вычислить с помощью метода \mc, который заключается в том, чтобы взять \emph{выборку} $x_1,\dots,x_n$ из распределения $X$ и аппроксимировать
\begin{equation}
\label{14:mc-approx}
\mu \approx \frac{1}{n} \sum_{i=1}^n x_i.
\end{equation}
Под выборкой понимается реализация случайных величин $X_1,\dots,X_n$, которые независимы и одинаково распределены с таким же распределением, как у $X$.

Обоснование аппроксимации \eqref{14:mc-approx} основано на (усиленном) законе больших чисел: если $\E X$ конечно, то тогда
\[
\lim_{n\to\infty} \frac{1}{n} \sum_{i=1}^n X_i = \mu\ \as
\] 
Поэтому при больших $n$ \emph{выборочное среднее} $\bar x = \frac{1}{n} \sum\limits_{i=1}^n x_i$ будет близко к $\mu$.

Для оценки точности приближения воспользуемся центральной предельной теоремой.
Пусть $X$ имеет конечное стандартное отклонение $\sigma$.
Тогда, согласно ЦПТ, имеет место сходимость
\[
Z_n := \frac{\sqrt{n}(\bar X_n - \mu)}{\sigma} \to \mathcal{N}(0,1)\ \text{по распределению},
\]
где $\bar X_n = \frac1n (X_1 + \ldots + X_n)$. 

Зададим вероятность $p\in (0,1)$, достаточно близкую к 1, и обозначим за $z$ квантиль стандартного нормального распределения уровня $(1+p)/2$ (таким образом, $\P(Z<z) = (1+p)/2$, или эквивалентно, $\P(|Z|<z) =p$, где $Z\sim \mathcal{N}(0,1)$).
Тогда из предыдущего соотношения следует, что $\P(|Z_n| < z) \approx p$ при больших $n$, откуда получаем 
\begin{equation}
\label{14:ci}
\mu \in \left[ \bar X_n - z \frac{\sigma}{\sqrt{n}},\ \bar X_n + z \frac{\sigma}{\sqrt{n}} \right]\ 
\text{с вероятностью примерно}\ p.
\end{equation}
Итак, настоящее значение $\mu$ будет лежать в пределах $\pm z \frac{\sigma}{\sqrt{n}}$ от выборочного среднего с вероятностью близкой к $p$.
Часто берут $z=3$, что соответствует $p\approx 0.997$ или $z=2$ для $p\approx 0.95$.

Однако значение $\sigma$ обычно тоже не известно.
В этом случае в формуле \eqref{14:ci} заменяют $\sigma$ на выборочное стандартное отклонение\footnote{Здесь для простоты используется смещенная оценка стандартного отклонения.
Чтобы получалась несмещенная оценка, в знаменателе дроби под корнем должно стоять $n-1$ вместо $n$.
Так как при использовании метода \mc\ $n$ велико, то разница несущественна.}
\[
s = \sqrt{\frac1n \sum_{i=1}^n (x_i - \bar x)^2}.
\]
Величина
\begin{equation}
\label{mc:error}
\epsilon = z \frac{s}{\sqrt{n}}
\end{equation}
называется \emph{выборочной ошибкой} метода \mc\ для данной выборки.

В результата, можно подытожить, что метод \mc\ заключается в том, чтобы получить выборку размера $n$ из распределения $X$ и оценить $\mu\approx \bar x$, при этом ошибка оценки будет равна $\epsilon = z s/ \sqrt{n}$.

\begin{remark}
Из выражения для $\epsilon$ видно, что для уменьшения ошибки в $k$ раз нужно увеличить размер выборки в $k^2$ раз.
На практике это означает, что метод \mc\ обладает низкой точностью\footnote{Чтобы получить следующий знак после запятой, нужно в 100 раз больше симуляций.}.
С другой стороны, он достаточно прост в реализации и может применяться для широкого класса задач.
Использование метода \mc\ оправдано, когда другие методы не применимы или труднореализуемы.
\end{remark}


\subsection{Алгоритм с контролем точности оценки}

Зададим доверительную вероятность $p$ и желаемую максимальную ошибку $\epsilon$.
Так как величина $\sigma$, как правило, не известна, то заранее нельзя сказать, сколько симуляций потребуется для достижения заданной точности.
Поэтому симуляции продолжают до тех пор, пока не будет выполнено условие
\begin{equation}
\label{14:abs-error}
z \frac{s}{\sqrt{n}} \le \epsilon.
\end{equation}
Это условие нужно проверять на каждом шаге симуляции (после получения очередного значения $x_n$) и останавливаться, когда оно выполнено.

Чтобы каждый раз не пересчитывать $\bar x$ и $s$ по всей выборке и не хранить выборку, пользуются  рекуррентными формулами 
\[
\bar x_{n+1} = \frac{n \bar x_n + x_{n+1}}{n+1}, \qquad
s_{n+1} = \sqrt{\overline{x_{n+1}^2} - (\bar x_{n+1})^2},
\]
где $\overline{x_n^2} =\frac 1n \sum\limits_{i=1}^n x_i^2$ (среднее квадратов элементов выборки) удовлетворяет рекуррентному соотношению
\[
\overline{x_{n+1}^2} = \frac{n\overline{x_n^2} + x_{n+1}^2}{n+1}.
\]

\begin{remark}
Критерий остановки симуляций \eqref{14:abs-error} соответствует оценке абсолютной ошибки, т.е.\ требует выполнения неравенства $|\bar x - \mu| \le \epsilon$.
Часто также бывает необходимо контролировать относительную ошибку: для этого вместо неравенства \eqref{14:abs-error} нужно использовать критерий
\begin{equation}
\label{14:rel-error}
z \frac{s}{\sqrt{n}} \le \epsilon |\bar x|.
\end{equation}

Обычно также ограничивают время работы алгоритма или максимально допустимое количество симуляций $n$. 
Тогда при достижении этого предела алгоритм останавливается, даже если условие \eqref{14:abs-error} или \eqref{14:rel-error} не выполнено.
\end{remark}

\begin{remark}
Иногда оказывается эффективнее симулировать не по одному значению из выборки, а группами по $k$ значений%
\footnote{Например, когда симуляции выполняются параллельно.
Также необходимость в симуляции группами возникает, если использовать пакет NumPy в Python и пользоваться векторизацией для ускорения вычислений.}.
В этом случае приведенные рекуррентные формулы можно переписать следующим образом.

Обозначим за $\bar x_{(n)}$ и $s_{(n)}$ выборочное среднее и стандартное отклонение, вычисленные по первым $n$ группам из $k$ значений, т.е.
\[
\bar x_{(n)} = \frac{1}{kn} \sum_{i=1}^{kn} x_i, \qquad
s_{(n)} = \sqrt{\frac{1}{kn} \sum_{i=1}^{kn} (x_i - \bar x_{(n)})^2}.
\]
Тогда
\begin{gather*}
\bar x_{(n+1)} = \frac{n\bar x_{(n)} + \frac1k (x_{kn+1}+\dots+x_{kn+k})}{n+1}, \\
s_{(n+1)} = \sqrt{\overline{x_{(n+1)}^2} - (\bar x_{(n+1)})^2},\qquad
\overline{x_{(n+1)}^2} = \frac{n\overline{x_{(n)}^2} + \frac1k (x_{kn+1}^2+\dots+x_{kn+k)}^2)}{n+1}.
\end{gather*}
\end{remark}


\section{Уменьшение дисперсии}

Чтобы уменьшить выборочную ошибку \mc\ и быстрее достичь заданной точности, можно уменьшить дисперсию симулируемой величины.
Рассматриваемые далее способы \emph{ускорения сходимости} метода \mc\ заключаются в том, чтобы вместо $X$ симулировать некоторую величину $X'$ имеющую такое же математическое ожидание, как и $X$, но меньшую дисперсию.
Более подробное изложение методов уменьшения дисперсии можно найти в главе~4 книги \cite{Glasserman03}.


% \subsection{Противоположные переменные}
% Предположим, что $X=f(Y)$, где $f(y)$ "--- монотонная функция, а $Y$ "--- случайная величина с таким распределением, что найдется константа $c$ для которой $Y$ и $c-Y$ одинаково распределены.
% Например, если $Y$ имеет стандартное нормальное распределение, то $c=0$; если $Y$ имеет равномерное распределение на отрезке $[0,1]$, то $c=1$. 

% Так как $f(Y)$ и $f(c-Y)$ одинаково распределены, то возьмем $X'= (f(Y) + f(c-Y))/2$.
% Тогда $\E X' = \E X$.
% Получим оценку на дисперсию $\D X'$.

% \begin{proposition}[интегральное неравенство Чебышёва]
% Пусть функция $f(x)$ не убывает, а функция $g(x)$ не возрастает.
% Тогда для любой случайной величины $X$ выполнено неравенство $\cov(f(X),g(X)) \le 0$ (при условии, что их ковариация определена и конечна).
% \end{proposition}

% Применим это неравенство к функции $g(y) = f(c-y)$. Тогда 
% \begin{multline*}
% \D X' =\frac{\D f(Y) + 2 \cov(f(Y),f(c-Y)) + \D f(c-Y)}{4} \\
% \le \frac{\D f(Y) + \D f(c-Y)}{4} 
% = \frac {\D f(Y)}{2} = \D\left(\frac{X_1+ X_2}{2}\right),
% \end{multline*}
% где $X_1$ и $X_2$ независимы и распределены так же, как $X$. Следовательно, вместо того, чтобы симулировать две независимых реализации $X$, выгоднее симулировать одну и использовать $X'$. Помимо того, что это уменьшает дисперсию, это еще и экономит время, необходимое на одну симуляцию.

% Таким образом, метод состоит в том, чтобы вместо выборки $x_1,x_2,\dots, x_{2n}$ брать выборку $x_1',x_2',\dots, x_{n}'$, где $x_i'=(f(y_i) + f(c-y_i))/2$. 

% \begin{remark}
% Если условие монотонности не выполнено, то дисперсия $X'$ может оказаться больше, чем $\D ((X_1+X_2)/2)$, но в любом случае она не превосходит $\D X$ (это видно из предыдущей формулы "--- максимальная дисперсия будет, когда коэффициент корреляции $f(Y)$ и $f(x-Y)$ равен 1). 
% На практике, даже для немонотонных функций метод противоположных переменных дает хорошее ускорение сходимости \mc.
% \end{remark}


\subsection{Контрольная переменная}

Будем искать $X'$ в виде $X' = X - \theta Y$, где $Y$ --- некоторая случайная величина с $\E Y = 0$ и $\cov(X,Y)\neq0$, а $\theta$ -- константа, которую нужно выбрать оптимальным образом.
Величина $Y$ называется \emph{контрольной переменной}.
Часто берут $Y= f(X)$ для некоторой функции $f$, которую нужно подобрать так, чтобы гарантировать условие $\E f(X) = 0$ (ее выбор зависит от структуры задачи).

\begin{proposition}
Пусть $X$ и $Y$ имеют конечные дисперсии, причем $\E Y = 0$.
Тогда минимум дисперсии величины $X' = X - \theta Y$ достигается при 
\begin{equation}
\label{14:theta}
\theta = \frac{\cov(X,Y)}{D(Y)}.
\end{equation}
\end{proposition}

\begin{proof}
Результат следует из того, что $\D X' = \D X - 2\theta \cov(X,Y) + \theta^2 \D Y$, а дальше нужно минимизировать эту функции по $\theta$.
\end{proof}

Итак, для использования метода контрольной переменной нужно выбрать $\theta$ по формуле \eqref{14:theta}.
Однако она содержит величины $\cov(X,Y)$ и $\D Y$, которые обычно неизвестны.
Вместо них можно использовать оценки, полученные тоже по методу \mc, но на основе выборки небольшого размера (т.е.\ сначала предварительный метод \mc\ применяют для оценки $\cov(X,Y)$ и $\D Y$, а затем уже  симулируют $X'$).
А именно, если имеется выборка пар значений $(x_i,y_i)$ размера $m$, то в качестве оценки $\theta$ возьмем
\[
\theta \approx \frac{\sum_{i=1}^m (x_i - \bar x)(y_i - \bar y)}{\sum_{i=1}^m (y_i - \bar y)^2}.
\]


\subsection{Выборка по значимости}
Пусть величина $X$ задана на вероятностном пространстве $(\Omega,\F,\P)$, а $\tilde\P$ "--- вероятностная мера, эквивалентная $\P$ ($\tilde\P\sim\P$; про эквивалентность мер см.~раздел \ref{ito-pr:ss:girsanov}).
Возьмем
\[
X' = X \frac{d\P}{d\tilde\P},
\]
где $d\P/d\tilde\P$ "--- производная Радона"--~Никодима.
Тогда
\[
\E^{\P} X = \E^{\tilde\P} X'.
\]
Таким образом, можно симулировать величину $X'$ по мере $\tilde\P$.
При этом дисперсия $X'$ будет равна
\[
\D^{\tilde \P} X' = \E^{\tilde\P} (X')^2 - (\E^{\tilde\P} X')^2 = \E^{\P} \left(X^2 \frac{d\P}{d\tilde\P}\right) -(\E^{\P} X)^2,
\]
и она будет меньше, чем $\D^\P X$, если $\E^\P(X^2 \frac{d\P}{d\tilde\P}) < \E^\P X^2$. 

В применениях метода \mc\ в финансовой математике $X$ часто задается функцией от случайной величины со стандартным нормальным распределением, $X = f(\xi)$, гдe $\xi\sim N(0,1)$ (или функцией от случайного вектора со стандартным многомерным нормальным распределением, $X=f(\xi_1,\dots,\xi_k)$, $\xi\sim N(0,I)$).
Тогда, если перейти к мере $\tilde\P$, заданной по формуле (в случае одномерной $\xi$)
\[
d\tilde\P = e^{\mu \xi - \frac12\mu^2} d\P,
\]
то относительно $\tilde\P$ величина $\xi$ будет иметь распределение $N(\mu,1)$ (это следует из замечания \ref{mc:r:measure-change} ниже, примененного к плотностям $p(x)=\frac{1}{\sqrt{2\pi}} e^{-x^2/2}$ и $\tilde p(x) = \frac{1}{\sqrt{2\pi}} e^{-(x-\mu)^2/2}$).
Следовательно, нужно симулировать
\[
X' = f(\xi) e^{-\mu \xi + \frac12\mu^2}, \qquad \xi\sim N(\mu,1),
\]
или, эквивалентно,
\[
X' = f(\xi+\mu) e^{-\mu \xi - \frac12\mu^2}, \qquad \xi\sim N(0,1).
\]
В многомерном случае, рассматривая меру $\P$, относительно которой вектор $\xi$ имеет независимые компоненты с распределением $\xi_i \sim N(\mu_i,1)$, получаем, что можно симулировать величину
\[
X' = f(\xi + \bar\mu) e^{\sum_i \mu_i\xi_i - \frac{1}{2}\sum_i \mu_i^2}, \qquad \xi \sim N(0,I),\ \bar\mu=(\mu,\dots,\mu).
\]

\begin{remark}
\label{mc:r:measure-change}
Полезно помнить следующее правило замены меры.
Если относительно $\P$ случайная величина $\xi$ имеет плотность распределения $p(x)$ и необходимо найти меру $\tilde\P$ такую, что относительно нее $\xi$ имеет плотность распределения $\tilde p(x)$, то 
\[
\frac{d\P}{d\tilde \P} = \frac{p(\xi)}{\tilde p(\xi)} \qquad
\left[\text{эквивалентно,}\quad \frac{d\tilde\P}{d \P} = \frac{\tilde p(\xi)}{p(\xi)} \right]
\]
(при условии, что у плотностей $p$ и $\tilde p$ совпадают носители).
Это показывается просто: зададим меру $\tilde \P = p(\xi)/\tilde p(\xi)d\P$ и получим, что для любого борелевского множества $A\subseteq \R$ верно равенство
\[
\tilde\P(\xi\in A) = \E^{\tilde\P}\I(\xi\in A) = \E^\P \left(\I(\xi\in A) \frac{d\tilde\P}{d\P}\right) = 
\int_A \frac{\tilde p(x)}{p(x)} p(x) dx = \int_A \tilde p(x) dx,
\]
а это и означает, что $\xi$ имеет плотность распределения $\tilde p$ относительно $\tilde\P$.
\end{remark}


\subsection{Пример}

Пусть $X=(e^{\sigma \xi - \sigma^2/2} - K)^+$, где $\xi\sim N(0,1)$.
Используя метод \mc, вычислим $\E X$ для $K\in \{1,\,1.2,\,1.4,\, 1.6\}$ при $\sigma=0.3$.
Можно заметить, что эти ожидания представляют собой цены европейских опционов колл с моментом экспирации $T=1$ и соответствущим страйком в модели \bs\ с нулевой безрисковой ставкой, волатильностью $\sigma$ и единичной начальной ценой рискового актива%
\footnote{В этом примере, конечно, можно найти точное значение $\E X$ по формуле \bs.}.

Таблица \ref{mc:t:example} показывает относительные ошибки \mc\ c выборкой размера $n=10\,000$ для разных способов уменьшением дисперсии, где под относительной ошибкой понимается величина $(\epsilon/\E X) \cdot 100\%$, а $\epsilon = 3\sqrt{\D X / n}$ "--- абсолютная ошибка (см.~формулу \eqref{mc:error}).

В методе контрольных переменных была использована величина $Y=S-1$, а в методе выборки по значимости использовалась мера $\tilde \P$, относительно которой $\xi\sim(\mu,1)$, где $\mu=\ln(K)/\sigma$, так что $\E^{\tilde\P} e^{\sigma\xi - \sigma^2/2} = K$.

%Видно, что например, для $K=1.6$ комбинация методов противоположных переменных и выборки по значимости позволила повысить скорость метода более, чем в 100 раз (так как точность повысилась более, чем в 10 раз, 20.1\% до 1.6\%, а точность пропорциональна корню из размера выборки).



\begin{table}[h]
\centering
\begin{tabular}{|p{6.5cm}|c|c|c|c|}
\hline
Метод & $K=1$ & $K=1.2$ & $K=1.4$ & $K=1.6$ \\\hline
Без уменьшения дисперсии &
5.3\% & 8.2\% & 12.8\% & 20.1\% \\\hline
Контрольная переменная &
4.0\% & 6.7\% & 11.3\% & 18.7\% \\\hline
Выборка по значимости &
5.3\% & 4.1\% & 3.8\% & 3.7\% \\\hline
Контрольная переменная + выборка по значимости &
3.1\% & 2.0\% & 1.6\% & 1.6\% \\\hline
\end{tabular}
\caption{Сравнение методов уменьшения дисперсии.}
\label{mc:t:example}  
\end{table}


\section{Применение к модели Блэка--Шоулза}

С помощью метода Монте--Карло можно легко (но медленно) вычислять цены европейских платежных обязательств, выплаты которых зависят от всей траектории процесса цены базового актива.
Пусть выплата производится в момент времени $T$ и имеет вид
\[
X = f(s_0, S_{t_1}, \dots, S_{t_m}),
\]
где $0 < t_1 < \dots < t_m \le T$ и $s_0$ -- начальная цена базового актива.
Чтобы найти цену платежного обязательства в момент времени $t=0$, нужно вычислить $V = B_T^{-1}\E^{\Q} X$.
Для применения метода Монте--Карло будем симулировать  величину $X$. 
В пакетах для численных методов обычно имеются функции симулирования стандартных нормальных случайных величин.
Тогда для симуляции одного значения $x$ величины $X$ получим выборку $z_1,\dots,z_m$ из стандартного нормального распределения и положим
\[
x = f(s_1,\dots,s_m), \qquad
s_i = s_{i-1} \exp\left(\sigma z_i \sqrt{t_i - t_{i-1}}  + \left(r-\frac{\sigma^2}{2}\right)(t_i - t_{i-1})\right).
\]
Если процентная ставка зависит от времени или актив платит дивиденды, то член $(r-\frac{\sigma^2}{2})(t_i - t_{i-1})$ в экспоненте нужно заменить на $\int_{t_{i-1}}^{t_i} (r(s) - q(s) - \frac{\sigma^2}{2}) ds$.

Нетрудно видеть, что значения $s_0,s_1,\dots,s_m$ представляют реализацию процесса цены $S_t$ в точках $0,t_1,\dots,t_m$ по эквивалентной мартингальной мере.
Следовательно, $x$ является выборочным значением величины $X$.

В качестве контрольной переменной можно взять, например,
\[
Y = \frac{S_T}{B_T} - s_0. 
\]
Также можно использовать разность дисконтированной выплаты некоторого платежного обязательства и его цены в начальный момент времени, например
\[
Y = \frac{(S_T-K)^+}{B_T} - C(T,K),
\]
где $C(T,K)$ -- цена опциона колл.


\summary

\begin{itemize}
\item Метод \mc\ заключается в аппроксимации значения $\E X$ выборочным средним $\bar x = \frac1n (x_1+\ldots + x_n)$, при этом ошибка аппроксимации составляет $zs/\sqrt{n}$, гдe $z$ "--- квантиль нормального распределения нужного уровня значимости (часто $z=2$ или $z=3$), а $s$ "--- выборочное стандартное отклонение.

\item Метод \mc\ "--- медленный. Он имеет точность порядка $1/\sqrt{n}$, \te\ для уменьшения ошибки в $k$ раз нужно увеличить размер выборки в $k^2$ раз.
Применение метода \mc\ оправдано, когда нет другого способа.

\item Для ускорения метода \mc\ применяют различные техники уменьшения дисперсии симулируемой величины: в лекции рассмотрены контрольные переменные и выборка по значимости.

\item В модели \bs\ метод \mc\ позволяет вычислять цены платежных обязательств зависящих от траектории цены рискового актива произвольным образом.
\end{itemize}
